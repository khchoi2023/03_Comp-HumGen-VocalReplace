{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "from logger import utils\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pydub import AudioSegment\n",
    "from logger.utils import traverse_dir\n",
    "\n",
    "# Cuda setting\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# configure loading\n",
    "args = utils.load_config('./configs/sins.yaml')\n",
    "\n",
    "# set path\n",
    "MP4_DATA_PATH   = 'preprocess/mp4'\n",
    "ORIGINAL_PATH   = 'preprocess/original/'\n",
    "DEMUCS_PATH     = 'preprocess/demucs/'\n",
    "NORM_PATH       = 'preprocess/norm/'\n",
    "TEMP_LOG_PATH   = 'temp_ffmpeg_log.txt'  # ffmpeg의 무음 감지 로그의 임시 저장 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.데이터 전처리\n",
    "***\n",
    "1. 난 전처리가 필요없다. 배경음 제거가 완벽하고, 모든 데이터들도 특정 길이로 잘 잘려져있다.\n",
    "    - 데이터를 전부 data/train/audio/안에 다 집어 넣고\n",
    "        ```\n",
    "        # training dataset\n",
    "        data/train/audio/aaa.wav\n",
    "        data/train/audio/bbb.wav\n",
    "        ...\n",
    "        ```\n",
    "    - 1.6 validation 분리단계로 점프\n",
    "***\n",
    "2. 난 거의 다 되어 있지만 데이터가 너무 길다. 특정 길이로 자르고 싶다.\n",
    "    - 데이터를 전부 preprocess/split 안에 다 집어 넣고\n",
    "        ```\n",
    "        # training dataset\n",
    "        preprocess/norm/aaa.wav\n",
    "        preprocess/norm/bbb.wav\n",
    "        ...\n",
    "        ```\n",
    "    - 1.4 split 단계로 점프\n",
    "***\n",
    "3. 난 배경음도 제거해야되고 데이터도 길다. 거의 날 것의 상태다.\n",
    "    - 데이터를 전부 preprocess/original 안에 다 집어넣고\n",
    "        ```\n",
    "        # training dataset\n",
    "        preprocess/original/aaa.wav\n",
    "        preprocess/original/bbb.wav\n",
    "        ...\n",
    "        ```\n",
    "    - 1.2부터 demucs 단계로 점프\n",
    "***\n",
    "4. 난 아무것도 안되어 있고, 심지어 mp4파일이다.\n",
    "    - 데이터들 전부 preprocess/mp4에 다 집어넣고\n",
    "        ```\n",
    "        # training dataset\n",
    "        preprocess/mp4/aaa.mp4\n",
    "        preprocess/mp4/bbb.mp4\n",
    "        ...\n",
    "        ```\n",
    "    - 1.1부터 차례대로 진행"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1데이터가 mp4인 경우 (wav만 있는 경우에는 패스)\n",
    "preprocess/mp4 안에 있는 mp4파일을 wav로 변경 해서 preprocess/original 에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:04<00:00,  2.63it/s]\n"
     ]
    }
   ],
   "source": [
    "def mp4_to_wav(input_dir : str, input_file: str, output_dir: str):\n",
    "    \"\"\"mp4파일을 wav형식으로 변환합니다.\n",
    "    Args:\n",
    "        input_dir (str) : 입력 mp4파일의 path\n",
    "        input_file (str) : 입력 mp4파일의 이름\n",
    "        output_dir (str) : 출력 wav파일의 path\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(input_file)[1][1:]\n",
    "\n",
    "    if ext != \"mp4\":\n",
    "        return \n",
    "    else :\n",
    "        track = AudioSegment.from_file(os.path.join(input_dir,input_file),  format= 'mp4')\n",
    "        track = track.set_frame_rate(44100)\n",
    "        track.export(os.path.join(output_dir, input_file[:-4]+\".wav\"), format='wav')\n",
    "\n",
    "\n",
    "filelist =  traverse_dir(\n",
    "    MP4_DATA_PATH,\n",
    "    extension='mp4',\n",
    "    is_pure=True,\n",
    "    is_sort=True,\n",
    "    is_ext=True)\n",
    "\n",
    "for file in tqdm(filelist):\n",
    "    mp4_to_wav(MP4_DATA_PATH, file, ORIGINAL_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 무음제거 (Demucs)\n",
    "preprocess/original에 있는 wav파일들의 음악소리를 제거하고 목소리만 추출해서 preprocess/demucs 에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 10:33:16 | INFO | torchaudio.utils.download | The local file (C:\\Users\\NT550-048\\.cache\\torch\\hub\\torchaudio\\models\\hdemucs_high_trained.pt) exists. Skipping the download.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 44100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "목소리 추출 중...: 100%|██████████| 67/67 [2:54:42<00:00, 156.46s/it]  \n"
     ]
    }
   ],
   "source": [
    "from sep_wav import demucs\n",
    "\n",
    "demucs(ORIGINAL_PATH, DEMUCS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 normalize\n",
    "preprocess/demucs에 있는 배경음이 제거된 데이터들을 노멀라이즈 (sample rate값을 바꿀 수 있음) 해서 preprocess/norm에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "노멀라이징 작업 중...:   0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "노멀라이징 작업 중...: 100%|██████████| 67/67 [04:13<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from sep_wav import audio_norm\n",
    "\n",
    "for filepath in tqdm(glob(DEMUCS_PATH+\"*.wav\"), desc=\"노멀라이징 작업 중...\"):\n",
    "    filename = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    out_filepath = os.path.join(NORM_PATH, filename) + \".wav\"\n",
    "    audio_norm(filepath, out_filepath, sample_rate = 44100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 split\n",
    "preprocess/norm에 있는 노말라이즈된 데이터들을 15초 길이로 잘라서 data/train/audio에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "음원 자르는 중...: 100%|██████████| 67/67 [00:28<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "for filepath in tqdm(glob(NORM_PATH+\"*.wav\"), desc=\"음원 자르는 중...\"):\n",
    "    duration = librosa.get_duration(filename=filepath)\n",
    "    max_last_seg_duration = 0\n",
    "    sep_duration_final = 15\n",
    "    sep_duration = 15\n",
    "\n",
    "    while sep_duration > 4:\n",
    "        last_seg_duration = duration % sep_duration\n",
    "        if max_last_seg_duration < last_seg_duration:\n",
    "            max_last_seg_duration = last_seg_duration\n",
    "            sep_duration_final = sep_duration\n",
    "        sep_duration -= 1\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    out_filepath = os.path.join(args.data.train_path,\"audio\", f\"{filename}-%04d.wav\")\n",
    "    subprocess.run(f'ffmpeg -i \"{filepath}\" -f segment -segment_time {sep_duration_final} \"{out_filepath}\" -y', capture_output=True, shell=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 무음 제거\n",
    "data/train/audio에 있는 잘라진 음원들 중에 무음인 파일들을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "무음 제거 중...: 100%|██████████| 2331/2331 [02:00<00:00, 19.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from sep_wav import get_ffmpeg_args\n",
    "import subprocess\n",
    "\n",
    "for filepath in tqdm(glob(args.data.train_path+\"/audio/*.wav\"), desc=\"무음 제거 중...\"):\n",
    "    if os.path.exists(TEMP_LOG_PATH):\n",
    "        os.remove(TEMP_LOG_PATH)\n",
    "\n",
    "    ffmpeg_arg = get_ffmpeg_args(filepath)\n",
    "    subprocess.run(ffmpeg_arg, capture_output=True, shell=True)\n",
    "\n",
    "    start = None\n",
    "    end = None\n",
    "\n",
    "    with open(TEMP_LOG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            if \"lavfi.silence_start\" in line:\n",
    "                start = float(line.split(\"=\")[1])\n",
    "            if \"lavfi.silence_end\" in line:\n",
    "                end = float(line.split(\"=\")[1])\n",
    "\n",
    "    if start != None:\n",
    "        if start == 0 and end == None:\n",
    "            os.remove(filepath)\n",
    "            \n",
    "if os.path.exists(TEMP_LOG_PATH):\n",
    "        os.remove(TEMP_LOG_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 학습 데이터 중, 일부를 validaion용으로 자동으로 보내준다.\n",
    "- data/train/audio에 있는 데이터 중 일정 비율만큼 알아서 data/val/audio로 이동시켜준다\n",
    "    - 계산식은 다음과 같다 `max(2, min(10, 전체 데이터 * 0.01))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from draw import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1110.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from draw import main\n",
    "\n",
    "main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 (학습에 쓰기 위한)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess\n",
    "from ddsp.vocoder import F0_Extractor, Volume_Extractor, Units_Encoder\n",
    "from diffusion.vocoder import Vocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Encoder Model] HuBERT Soft\n",
      " [Loading] pretrain/hubert/hubert-soft-0d54a1f4.pt\n",
      "Preprocess the audio clips in : data/train\\audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 97/2089 [02:37<55:48,  1.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Error] F0 extraction failed: data/train\\audio\\07 김광석 (Kim Kwang Seok) - 기다려줘 (Please Wait for Me) (Official Audio) (2022 Remastered)-0000.wav\n",
      "This file has been moved to data/train\\skip\\07 김광석 (Kim Kwang Seok) - 기다려줘 (Please Wait for Me) (Official Audio) (2022 Remastered)-0000.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 353/2089 [09:48<49:06,  1.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Error] F0 extraction failed: data/train\\audio\\12 #### 김광석 (Kim Kwang Seok) - 1집 (First Album) (Full Track) (Official Audio) (2022 Remastered)-0177.wav\n",
      "This file has been moved to data/train\\skip\\12 #### 김광석 (Kim Kwang Seok) - 1집 (First Album) (Full Track) (Official Audio) (2022 Remastered)-0177.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1723/2089 [49:44<11:12,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Error] F0 extraction failed: data/train\\audio\\56 김광석 - 그녀가 처음 울던 날 (The Day When She Cried for the First Time) (Official Audio) (2022 Remastered)-0011.wav\n",
      "This file has been moved to data/train\\skip\\56 김광석 - 그녀가 처음 울던 날 (The Day When She Cried for the First Time) (Official Audio) (2022 Remastered)-0011.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1777/2089 [51:21<09:35,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Error] F0 extraction failed: data/train\\audio\\59 김광석 (Kim Kwang Seok) - 두 바퀴로 가는 자동차 (The Car with Two Tires) (Official Audio) (2022 Remastered)-0013.wav\n",
      "This file has been moved to data/train\\skip\\59 김광석 (Kim Kwang Seok) - 두 바퀴로 가는 자동차 (The Car with Two Tires) (Official Audio) (2022 Remastered)-0013.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1928/2089 [55:58<04:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Error] F0 extraction failed: data/train\\audio\\67 #### 김광석 (Kim Kwang Seok) - 다시 부르기 2 (Sing Again 2) (Full Track) (Official Audio) (2022 Remastered)-0031.wav\n",
      "This file has been moved to data/train\\skip\\67 #### 김광석 (Kim Kwang Seok) - 다시 부르기 2 (Sing Again 2) (Full Track) (Official Audio) (2022 Remastered)-0031.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2089/2089 [1:00:31<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess the audio clips in : data/val\\audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "from preprocess import preprocess\n",
    "from ddsp.vocoder import F0_Extractor, Volume_Extractor, Units_Encoder\n",
    "from diffusion.vocoder import Vocoder\n",
    "\n",
    "# get data\n",
    "sample_rate = args.data.sampling_rate\n",
    "hop_size = args.data.block_size\n",
    "\n",
    "# initialize f0 extractor\n",
    "f0_extractor = F0_Extractor(\n",
    "                    args.data.f0_extractor, \n",
    "                    args.data.sampling_rate, \n",
    "                    args.data.block_size, \n",
    "                    args.data.f0_min, \n",
    "                    args.data.f0_max)\n",
    "\n",
    "# initialize volume extractor\n",
    "volume_extractor = Volume_Extractor(args.data.block_size)\n",
    "\n",
    "# initialize mel extractor\n",
    "mel_extractor = None\n",
    "if args.model.type == 'Diffusion':\n",
    "    mel_extractor = Vocoder(args.vocoder.type, args.vocoder.ckpt, device = device)\n",
    "    if mel_extractor.vocoder_sample_rate != sample_rate or mel_extractor.vocoder_hop_size != hop_size:\n",
    "        mel_extractor = None\n",
    "        print('Unmatch vocoder parameters, mel extraction is ignored!')\n",
    "\n",
    "# initialize units encoder\n",
    "if args.data.encoder == 'cnhubertsoftfish':\n",
    "    cnhubertsoft_gate = args.data.cnhubertsoft_gate\n",
    "else:\n",
    "    cnhubertsoft_gate = 10             \n",
    "units_encoder = Units_Encoder(\n",
    "                    args.data.encoder, \n",
    "                    args.data.encoder_ckpt, \n",
    "                    args.data.encoder_sample_rate, \n",
    "                    args.data.encoder_hop_size, \n",
    "                    device = device)    \n",
    "\n",
    "# preprocess training set\n",
    "preprocess(args.data.train_path, f0_extractor, volume_extractor, mel_extractor, units_encoder, sample_rate, hop_size, device = device)\n",
    "\n",
    "# preprocess validation set\n",
    "preprocess(args.data.valid_path, f0_extractor, volume_extractor, mel_extractor, units_encoder, sample_rate, hop_size, device = device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >    exp: exp/sins-test\n",
      " [DDSP Model] Sinusoids Additive Synthesiser\n",
      " [*] restoring model from exp/sins-test\\model_42000.pt\n",
      "Load all the data from : data/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [01:32<00:00, 22.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load all the data from : data/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- model size ---\n",
      "model: 3,375,360\n",
      "======= start training =======\n",
      "epoch: 0 |   9/ 87 | exp/sins-test | batch/s: 0.09 | loss: 1.262 | time: 0:01:49.5 | step: 42010\n",
      "epoch: 0 |  19/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.159 | time: 0:03:05.2 | step: 42020\n",
      "epoch: 0 |  29/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.235 | time: 0:04:15.5 | step: 42030\n",
      "epoch: 0 |  39/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.222 | time: 0:05:28.7 | step: 42040\n",
      "epoch: 0 |  49/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.103 | time: 0:06:41.5 | step: 42050\n",
      "epoch: 0 |  59/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.142 | time: 0:07:51.2 | step: 42060\n",
      "epoch: 0 |  69/ 87 | exp/sins-test | batch/s: 0.11 | loss: 1.211 | time: 0:09:22.9 | step: 42070\n",
      "epoch: 0 |  79/ 87 | exp/sins-test | batch/s: 0.12 | loss: 1.223 | time: 0:10:43.1 | step: 42080\n",
      "epoch: 1 |   2/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.159 | time: 0:11:56.2 | step: 42090\n",
      "epoch: 1 |  12/ 87 | exp/sins-test | batch/s: 0.10 | loss: 1.104 | time: 0:13:38.2 | step: 42100\n",
      "epoch: 1 |  22/ 87 | exp/sins-test | batch/s: 0.11 | loss: 1.164 | time: 0:15:06.8 | step: 42110\n",
      "epoch: 1 |  32/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.089 | time: 0:16:25.6 | step: 42120\n",
      "epoch: 1 |  42/ 87 | exp/sins-test | batch/s: 0.11 | loss: 1.318 | time: 0:17:53.9 | step: 42130\n",
      "epoch: 1 |  52/ 87 | exp/sins-test | batch/s: 0.11 | loss: 1.223 | time: 0:19:22.6 | step: 42140\n",
      "epoch: 1 |  62/ 87 | exp/sins-test | batch/s: 0.11 | loss: 1.067 | time: 0:20:55.3 | step: 42150\n",
      "epoch: 1 |  72/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.172 | time: 0:22:14.0 | step: 42160\n",
      "epoch: 1 |  82/ 87 | exp/sins-test | batch/s: 0.12 | loss: 1.211 | time: 0:23:34.2 | step: 42170\n",
      "epoch: 2 |   5/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.157 | time: 0:24:50.4 | step: 42180\n",
      "epoch: 2 |  15/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.117 | time: 0:26:02.7 | step: 42190\n",
      "epoch: 2 |  25/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.220 | time: 0:27:14.2 | step: 42200\n",
      "epoch: 2 |  35/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.243 | time: 0:28:27.3 | step: 42210\n",
      "epoch: 2 |  45/ 87 | exp/sins-test | batch/s: 0.12 | loss: 1.198 | time: 0:29:53.6 | step: 42220\n",
      "epoch: 2 |  55/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.180 | time: 0:31:10.0 | step: 42230\n",
      "epoch: 2 |  65/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.174 | time: 0:32:26.6 | step: 42240\n",
      "epoch: 2 |  75/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.190 | time: 0:33:42.4 | step: 42250\n",
      "epoch: 2 |  85/ 87 | exp/sins-test | batch/s: 0.12 | loss: 1.137 | time: 0:35:03.9 | step: 42260\n",
      "epoch: 3 |   8/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.146 | time: 0:36:18.6 | step: 42270\n",
      "epoch: 3 |  18/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.091 | time: 0:37:35.6 | step: 42280\n",
      "epoch: 3 |  28/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.187 | time: 0:38:53.7 | step: 42290\n",
      "epoch: 3 |  38/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.125 | time: 0:40:10.4 | step: 42300\n",
      "epoch: 3 |  48/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.191 | time: 0:41:25.3 | step: 42310\n",
      "epoch: 3 |  58/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.231 | time: 0:42:40.1 | step: 42320\n",
      "epoch: 3 |  68/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.245 | time: 0:43:54.4 | step: 42330\n",
      "epoch: 3 |  78/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.347 | time: 0:45:10.0 | step: 42340\n",
      "epoch: 4 |   1/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.199 | time: 0:46:23.8 | step: 42350\n",
      "epoch: 4 |  11/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.237 | time: 0:47:39.7 | step: 42360\n",
      "epoch: 4 |  21/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.170 | time: 0:48:52.9 | step: 42370\n",
      "epoch: 4 |  31/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.099 | time: 0:50:07.2 | step: 42380\n",
      "epoch: 4 |  41/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.143 | time: 0:51:21.5 | step: 42390\n",
      "epoch: 4 |  51/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.168 | time: 0:52:33.6 | step: 42400\n",
      "epoch: 4 |  61/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.255 | time: 0:53:46.7 | step: 42410\n",
      "epoch: 4 |  71/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.165 | time: 0:55:00.7 | step: 42420\n",
      "epoch: 4 |  81/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.245 | time: 0:56:15.2 | step: 42430\n",
      "epoch: 5 |   4/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.108 | time: 0:57:27.6 | step: 42440\n",
      "epoch: 5 |  14/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.202 | time: 0:58:40.4 | step: 42450\n",
      "epoch: 5 |  24/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.094 | time: 0:59:56.0 | step: 42460\n",
      "epoch: 5 |  34/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.227 | time: 1:01:09.4 | step: 42470\n",
      "epoch: 5 |  44/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.187 | time: 1:02:24.9 | step: 42480\n",
      "epoch: 5 |  54/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.124 | time: 1:03:39.8 | step: 42490\n",
      "epoch: 5 |  64/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.105 | time: 1:04:55.7 | step: 42500\n",
      "epoch: 5 |  74/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.152 | time: 1:06:10.7 | step: 42510\n",
      "epoch: 5 |  84/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.128 | time: 1:07:24.7 | step: 42520\n",
      "epoch: 6 |   7/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.105 | time: 1:08:36.6 | step: 42530\n",
      "epoch: 6 |  17/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.169 | time: 1:09:46.5 | step: 42540\n",
      "epoch: 6 |  27/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.119 | time: 1:10:54.5 | step: 42550\n",
      "epoch: 6 |  37/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.206 | time: 1:12:03.5 | step: 42560\n",
      "epoch: 6 |  47/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.285 | time: 1:13:15.1 | step: 42570\n",
      "epoch: 6 |  57/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.308 | time: 1:14:27.2 | step: 42580\n",
      "epoch: 6 |  67/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.157 | time: 1:15:40.1 | step: 42590\n",
      "epoch: 6 |  77/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.198 | time: 1:16:56.0 | step: 42600\n",
      "epoch: 7 |   0/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.209 | time: 1:18:12.3 | step: 42610\n",
      "epoch: 7 |  10/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.165 | time: 1:19:30.0 | step: 42620\n",
      "epoch: 7 |  20/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.085 | time: 1:20:46.7 | step: 42630\n",
      "epoch: 7 |  30/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.127 | time: 1:22:00.5 | step: 42640\n",
      "epoch: 7 |  40/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.092 | time: 1:23:14.7 | step: 42650\n",
      "epoch: 7 |  50/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.161 | time: 1:24:23.7 | step: 42660\n",
      "epoch: 7 |  60/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.176 | time: 1:25:35.4 | step: 42670\n",
      "epoch: 7 |  70/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.166 | time: 1:26:44.8 | step: 42680\n",
      "epoch: 7 |  80/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.209 | time: 1:27:53.5 | step: 42690\n",
      "epoch: 8 |   3/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.175 | time: 1:29:01.7 | step: 42700\n",
      "epoch: 8 |  13/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.200 | time: 1:30:13.7 | step: 42710\n",
      "epoch: 8 |  23/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.186 | time: 1:31:25.4 | step: 42720\n",
      "epoch: 8 |  33/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.150 | time: 1:32:34.1 | step: 42730\n",
      "epoch: 8 |  43/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.190 | time: 1:33:42.6 | step: 42740\n",
      "epoch: 8 |  53/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.107 | time: 1:34:51.7 | step: 42750\n",
      "epoch: 8 |  63/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.152 | time: 1:36:00.0 | step: 42760\n",
      "epoch: 8 |  73/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.319 | time: 1:37:07.0 | step: 42770\n",
      "epoch: 8 |  83/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.251 | time: 1:38:18.2 | step: 42780\n",
      "epoch: 9 |   6/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.250 | time: 1:39:24.7 | step: 42790\n",
      "epoch: 9 |  16/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.088 | time: 1:40:32.3 | step: 42800\n",
      "epoch: 9 |  26/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.216 | time: 1:41:41.3 | step: 42810\n",
      "epoch: 9 |  36/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.093 | time: 1:42:51.6 | step: 42820\n",
      "epoch: 9 |  46/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.174 | time: 1:44:02.8 | step: 42830\n",
      "epoch: 9 |  56/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.162 | time: 1:45:12.1 | step: 42840\n",
      "epoch: 9 |  66/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.205 | time: 1:46:22.0 | step: 42850\n",
      "epoch: 9 |  76/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.082 | time: 1:47:34.2 | step: 42860\n",
      "epoch: 9 |  86/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.243 | time: 1:48:44.8 | step: 42870\n",
      "epoch: 10 |   9/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.174 | time: 1:49:56.1 | step: 42880\n",
      "epoch: 10 |  19/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.168 | time: 1:51:08.3 | step: 42890\n",
      "epoch: 10 |  29/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.069 | time: 1:52:18.8 | step: 42900\n",
      "epoch: 10 |  39/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.186 | time: 1:53:28.8 | step: 42910\n",
      "epoch: 10 |  49/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.144 | time: 1:54:40.0 | step: 42920\n",
      "epoch: 10 |  59/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.126 | time: 1:55:48.4 | step: 42930\n",
      "epoch: 10 |  69/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.111 | time: 1:56:57.8 | step: 42940\n",
      "epoch: 10 |  79/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.265 | time: 1:58:08.0 | step: 42950\n",
      "epoch: 11 |   2/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.041 | time: 1:59:15.8 | step: 42960\n",
      "epoch: 11 |  12/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.149 | time: 2:00:24.2 | step: 42970\n",
      "epoch: 11 |  22/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.128 | time: 2:01:33.6 | step: 42980\n",
      "epoch: 11 |  32/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.219 | time: 2:02:43.0 | step: 42990\n",
      "epoch: 11 |  42/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.112 | time: 2:03:51.3 | step: 43000\n",
      "epoch: 11 |  52/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.181 | time: 2:05:00.0 | step: 43010\n",
      "epoch: 11 |  62/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.119 | time: 2:06:08.9 | step: 43020\n",
      "epoch: 11 |  72/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.153 | time: 2:07:17.1 | step: 43030\n",
      "epoch: 11 |  82/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.121 | time: 2:08:25.8 | step: 43040\n",
      "epoch: 12 |   5/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.098 | time: 2:09:33.5 | step: 43050\n",
      "epoch: 12 |  15/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.219 | time: 2:10:46.2 | step: 43060\n",
      "epoch: 12 |  25/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.176 | time: 2:11:58.0 | step: 43070\n",
      "epoch: 12 |  35/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.136 | time: 2:13:12.3 | step: 43080\n",
      "epoch: 12 |  45/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.356 | time: 2:14:23.8 | step: 43090\n",
      "epoch: 12 |  55/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.082 | time: 2:15:33.5 | step: 43100\n",
      "epoch: 12 |  65/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.094 | time: 2:16:42.7 | step: 43110\n",
      "epoch: 12 |  75/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.370 | time: 2:17:50.9 | step: 43120\n",
      "epoch: 12 |  85/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.201 | time: 2:18:59.5 | step: 43130\n",
      "epoch: 13 |   8/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.141 | time: 2:20:07.8 | step: 43140\n",
      "epoch: 13 |  18/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.128 | time: 2:21:16.1 | step: 43150\n",
      "epoch: 13 |  28/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.318 | time: 2:22:27.6 | step: 43160\n",
      "epoch: 13 |  38/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.141 | time: 2:23:39.5 | step: 43170\n",
      "epoch: 13 |  48/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.189 | time: 2:24:49.7 | step: 43180\n",
      "epoch: 13 |  58/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.226 | time: 2:25:59.2 | step: 43190\n",
      "epoch: 13 |  68/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.095 | time: 2:27:07.9 | step: 43200\n",
      "epoch: 13 |  78/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.127 | time: 2:28:15.3 | step: 43210\n",
      "epoch: 14 |   1/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.128 | time: 2:29:21.7 | step: 43220\n",
      "epoch: 14 |  11/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.133 | time: 2:30:29.2 | step: 43230\n",
      "epoch: 14 |  21/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.322 | time: 2:31:40.4 | step: 43240\n",
      "epoch: 14 |  31/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.426 | time: 2:32:53.7 | step: 43250\n",
      "epoch: 14 |  41/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.083 | time: 2:34:10.0 | step: 43260\n",
      "epoch: 14 |  51/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.223 | time: 2:35:22.7 | step: 43270\n",
      "epoch: 14 |  61/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.132 | time: 2:36:31.9 | step: 43280\n",
      "epoch: 14 |  71/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.111 | time: 2:37:41.1 | step: 43290\n",
      "epoch: 14 |  81/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.204 | time: 2:38:51.2 | step: 43300\n",
      "epoch: 15 |   4/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.102 | time: 2:40:00.7 | step: 43310\n",
      "epoch: 15 |  14/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.093 | time: 2:41:15.8 | step: 43320\n",
      "epoch: 15 |  24/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.128 | time: 2:42:28.6 | step: 43330\n",
      "epoch: 15 |  34/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.107 | time: 2:43:41.0 | step: 43340\n",
      "epoch: 15 |  44/ 87 | exp/sins-test | batch/s: 0.13 | loss: 1.161 | time: 2:44:55.4 | step: 43350\n",
      "epoch: 15 |  54/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.123 | time: 2:46:06.8 | step: 43360\n",
      "epoch: 15 |  64/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.098 | time: 2:47:17.5 | step: 43370\n",
      "epoch: 15 |  74/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.195 | time: 2:48:27.7 | step: 43380\n",
      "epoch: 15 |  84/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.214 | time: 2:49:39.3 | step: 43390\n",
      "epoch: 16 |   7/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.178 | time: 2:50:48.4 | step: 43400\n",
      "epoch: 16 |  17/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.201 | time: 2:51:59.4 | step: 43410\n",
      "epoch: 16 |  27/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.068 | time: 2:53:09.3 | step: 43420\n",
      "epoch: 16 |  37/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.224 | time: 2:54:21.8 | step: 43430\n",
      "epoch: 16 |  47/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.192 | time: 2:55:32.3 | step: 43440\n",
      "epoch: 16 |  57/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.095 | time: 2:56:43.4 | step: 43450\n",
      "epoch: 16 |  67/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.177 | time: 2:57:54.0 | step: 43460\n",
      "epoch: 16 |  77/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.159 | time: 2:59:04.5 | step: 43470\n",
      "epoch: 17 |   0/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.065 | time: 3:00:14.3 | step: 43480\n",
      "epoch: 17 |  10/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.258 | time: 3:01:25.6 | step: 43490\n",
      "epoch: 17 |  20/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.055 | time: 3:02:37.8 | step: 43500\n",
      "epoch: 17 |  30/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.159 | time: 3:03:49.3 | step: 43510\n",
      "epoch: 17 |  40/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.107 | time: 3:05:01.3 | step: 43520\n",
      "epoch: 17 |  50/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.043 | time: 3:06:10.0 | step: 43530\n",
      "epoch: 17 |  60/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.075 | time: 3:07:19.2 | step: 43540\n",
      "epoch: 17 |  70/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.157 | time: 3:08:28.1 | step: 43550\n",
      "epoch: 17 |  80/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.136 | time: 3:09:37.5 | step: 43560\n",
      "epoch: 18 |   3/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.221 | time: 3:10:48.7 | step: 43570\n",
      "epoch: 18 |  13/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.150 | time: 3:11:58.6 | step: 43580\n",
      "epoch: 18 |  23/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.116 | time: 3:13:10.2 | step: 43590\n",
      "epoch: 18 |  33/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.116 | time: 3:14:18.0 | step: 43600\n",
      "epoch: 18 |  43/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.159 | time: 3:15:26.5 | step: 43610\n",
      "epoch: 18 |  53/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.167 | time: 3:16:36.8 | step: 43620\n",
      "epoch: 18 |  63/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.520 | time: 3:17:45.6 | step: 43630\n",
      "epoch: 18 |  73/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.174 | time: 3:18:53.5 | step: 43640\n",
      "epoch: 18 |  83/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.126 | time: 3:20:03.8 | step: 43650\n",
      "epoch: 19 |   6/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.145 | time: 3:21:10.1 | step: 43660\n",
      "epoch: 19 |  16/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.162 | time: 3:22:18.4 | step: 43670\n",
      "epoch: 19 |  26/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.124 | time: 3:23:25.4 | step: 43680\n",
      "epoch: 19 |  36/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.228 | time: 3:24:33.0 | step: 43690\n",
      "epoch: 19 |  46/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.072 | time: 3:25:42.4 | step: 43700\n",
      "epoch: 19 |  56/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.119 | time: 3:26:54.6 | step: 43710\n",
      "epoch: 19 |  66/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.269 | time: 3:28:05.8 | step: 43720\n",
      "epoch: 19 |  76/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.075 | time: 3:29:13.9 | step: 43730\n",
      "epoch: 19 |  86/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.114 | time: 3:30:20.9 | step: 43740\n",
      "epoch: 20 |   9/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.064 | time: 3:31:29.5 | step: 43750\n",
      "epoch: 20 |  19/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.255 | time: 3:32:38.2 | step: 43760\n",
      "epoch: 20 |  29/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.107 | time: 3:33:47.7 | step: 43770\n",
      "epoch: 20 |  39/ 87 | exp/sins-test | batch/s: 0.15 | loss: 1.128 | time: 3:34:56.0 | step: 43780\n",
      "epoch: 20 |  49/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.172 | time: 3:36:05.3 | step: 43790\n",
      "epoch: 20 |  59/ 87 | exp/sins-test | batch/s: 0.14 | loss: 1.106 | time: 3:37:14.3 | step: 43800\n"
     ]
    }
   ],
   "source": [
    "from train import ddsp_train\n",
    "\n",
    "ddsp_train(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 결과물 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from main import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [DDSP Model] Sinusoids Additive Synthesiser\n",
      " [Loading] exp/sins-test/model_42000.pt\n",
      "MD5: 29858198b44cde1695beaffe7fecff7a\n",
      "Loading pitch curves for input audio from cache directory...\n",
      "Extracting the volume envelope of the input audio...\n",
      " [Encoder Model] HuBERT Soft\n",
      " [Loading] pretrain/hubert/hubert-soft-0d54a1f4.pt\n",
      "Enhancer type: nsf-hifigan\n",
      "| Load HifiGAN:  pretrain/nsf_hifigan/model\n",
      "Removing weight norm...\n",
      "Speaker ID: 1\n",
      "Cut the input audio into 23 slices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [03:39<00:00,  9.53s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# configure setting\n",
    "configures = {\n",
    "    'model_path'            :   \"exp/sins-test/model_42000.pt\", # 추론에 사용하고자 하는 모델, 바로위에서 학습한 모델을 가져오면댐\n",
    "    'input'                 :   \"data/test/천년의사랑_vocals.wav\", # 추론하고자 하는 노래파일의 위치 - 님들이 바꿔야댐 \n",
    "    'output'                :   'data/김광석_ddsp_천년의사랑_42000.wav',  # 결과물 파일의 위치\n",
    "    'device'                :   'cpu',\n",
    "    'spk_id'                :   '1', \n",
    "    'spk_mix_dict'          :   'None', \n",
    "    'key'                   :   '0', \n",
    "    'enhance'               :   'true' , \n",
    "    'pitch_extractor'       :   'crepe' ,\n",
    "    'f0_min'                :   '50' ,\n",
    "    'f0_max'                :   '1100',\n",
    "    'threhold'              :   '-60',\n",
    "    'enhancer_adaptive_key' :   '0'\n",
    "}\n",
    "cmd = SimpleNamespace(**configures)\n",
    "\n",
    "inference(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8a643f5fe528358e1cfac3836870fd104c9c787e6f994a831162d9d1f5f0281"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
